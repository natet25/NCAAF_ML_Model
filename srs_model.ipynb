{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfb = pd.read_csv('CFBData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfb['id'] = cfb['name'] + '_' + cfb['year'].astype(str)\n",
    "\n",
    "def create_id(x):\n",
    "    ids = x.lower().split(' ')\n",
    "    return '_'.join(ids)\n",
    "\n",
    "cfb['id'] = cfb['id'].apply(create_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop any stats relating to wins, games, and any categorical\n",
    "cfb_stats = cfb[['first_downs',\n",
    "       'opponents_first_downs', 'first_downs_from_penalties',\n",
    "       'opponents_first_downs_from_penalties', 'fumbles_lost',\n",
    "       'opponents_fumbles_lost', 'interceptions',\n",
    "       'opponents_interceptions', 'pass_attempts',\n",
    "       'opponents_pass_attempts', 'pass_completion_percentage',\n",
    "       'opponents_pass_completion_percentage', 'pass_completions',\n",
    "       'opponents_pass_completions', 'pass_first_downs',\n",
    "       'opponents_pass_first_downs', 'pass_touchdowns',\n",
    "       'opponents_pass_touchdowns', 'pass_yards', 'opponents_pass_yards',\n",
    "       'penalties', 'opponents_penalties', 'plays', 'opponents_plays',\n",
    "       'points_against_per_game', 'points_per_game', 'rush_attempts',\n",
    "       'opponents_rush_attempts', 'rush_first_downs',\n",
    "       'opponents_rush_first_downs', 'rush_touchdowns',\n",
    "       'opponents_rush_touchdowns', 'rush_yards', 'opponents_rush_yards',\n",
    "       'rush_yards_per_attempt', 'opponents_rush_yards_per_attempt',\n",
    "       'simple_rating_system', 'strength_of_schedule', 'turnovers',\n",
    "       'opponents_turnovers', 'yards',\n",
    "       'opponents_yards', 'yards_from_penalties',\n",
    "       'opponents_yards_from_penalties', 'yards_per_play',\n",
    "       'opponents_yards_per_play']].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X = cfb_stats.drop('simple_rating_system', axis = 1)\n",
    "y = cfb_stats['simple_rating_system']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "baseline = LinearRegression()\n",
    "baseline.fit(X_train, y_train)\n",
    "y_pred = baseline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = LinearRegression()\n",
    "baseline.fit(X_train, y_train)\n",
    "y_pred = baseline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 2.5204027090418504\n",
      "mae 1.2826733675648974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('mse', mean_squared_error(y_test, y_pred))\n",
    "print('mae', mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfb_stats['first_downs_diff'] = cfb_stats['first_downs'] - cfb_stats['opponents_first_downs']\n",
    "cfb_stats['first_downs_from_penalties_diff'] = cfb_stats['first_downs_from_penalties'] - cfb_stats['opponents_first_downs_from_penalties']\n",
    "cfb_stats['fumbles_lost_diff'] = cfb_stats['fumbles_lost'] - cfb_stats['opponents_fumbles_lost']\n",
    "cfb_stats['interceptions_diff'] = cfb_stats['interceptions'] - cfb_stats['opponents_interceptions']\n",
    "cfb_stats['pass_attempts_diff'] = cfb_stats['pass_attempts'] - cfb_stats['opponents_pass_attempts']\n",
    "cfb_stats['pass_completion_percentage_diff'] = cfb_stats['pass_completion_percentage'] - cfb_stats['opponents_pass_completion_percentage']\n",
    "cfb_stats['pass_completion_diff'] = cfb_stats['pass_completions'] - cfb_stats['opponents_pass_completions']\n",
    "cfb_stats['pass_first_downs_diff'] = cfb_stats['pass_first_downs'] - cfb_stats['opponents_pass_first_downs']\n",
    "cfb_stats['pass_touchdowns_diff'] = cfb_stats['pass_touchdowns'] - cfb_stats['opponents_pass_touchdowns']\n",
    "cfb_stats['pass_yards_diff'] = cfb_stats['pass_yards'] - cfb_stats['opponents_pass_yards']\n",
    "cfb_stats['penalties_diff'] = cfb_stats['penalties'] - cfb_stats['opponents_penalties']\n",
    "cfb_stats['plays_diff'] = cfb_stats['plays'] - cfb_stats['opponents_plays']\n",
    "cfb_stats['score_differential'] = cfb_stats['points_per_game'] - cfb_stats['points_against_per_game']\n",
    "cfb_stats['rush_attempts_diff'] = cfb_stats['rush_attempts'] - cfb_stats['opponents_rush_attempts']\n",
    "cfb_stats['rush_first_downs_diff'] = cfb_stats['rush_first_downs'] - cfb_stats['opponents_rush_first_downs']\n",
    "cfb_stats['rush_touchdowns_diff'] = cfb_stats['rush_touchdowns'] - cfb_stats['opponents_rush_touchdowns']\n",
    "cfb_stats['rush_yards_diff'] = cfb_stats['rush_yards'] - cfb_stats['opponents_rush_yards']\n",
    "cfb_stats['rush_yards_per_attempt_diff'] = cfb_stats['rush_yards_per_attempt'] - cfb_stats['opponents_rush_yards_per_attempt']\n",
    "cfb_stats['turnovers_diff'] = cfb_stats['turnovers'] - cfb_stats['opponents_turnovers']\n",
    "cfb_stats['yards_diff'] = cfb_stats['yards'] - cfb_stats['opponents_yards']\n",
    "cfb_stats['yards_from_penalties_diff'] = cfb_stats['yards_from_penalties'] - cfb_stats['opponents_yards_from_penalties']\n",
    "cfb_stats['yards_per_play_diff'] = cfb_stats['yards_per_play'] - cfb_stats['opponents_yards_per_play']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfb_diff = cfb_stats.drop(['first_downs', 'opponents_first_downs', 'first_downs_from_penalties',\n",
    "       'opponents_first_downs_from_penalties', 'fumbles_lost',\n",
    "       'opponents_fumbles_lost', 'interceptions', 'opponents_interceptions',\n",
    "       'pass_attempts', 'opponents_pass_attempts',\n",
    "       'pass_completion_percentage', 'opponents_pass_completion_percentage',\n",
    "       'pass_completions', 'opponents_pass_completions', 'pass_first_downs',\n",
    "       'opponents_pass_first_downs', 'pass_touchdowns',\n",
    "       'opponents_pass_touchdowns', 'pass_yards', 'opponents_pass_yards',\n",
    "       'penalties', 'opponents_penalties', 'plays', 'opponents_plays',\n",
    "       'points_against_per_game', 'points_per_game', 'rush_attempts',\n",
    "       'opponents_rush_attempts', 'rush_first_downs',\n",
    "       'opponents_rush_first_downs', 'rush_touchdowns',\n",
    "       'opponents_rush_touchdowns', 'rush_yards', 'opponents_rush_yards',\n",
    "       'rush_yards_per_attempt', 'opponents_rush_yards_per_attempt',\n",
    "       'turnovers',\n",
    "       'opponents_turnovers', 'yards', 'opponents_yards',\n",
    "       'yards_from_penalties', 'opponents_yards_from_penalties',\n",
    "       'yards_per_play', 'opponents_yards_per_play'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfb_diff['id'] = cfb['id']\n",
    "cfb_diff['team'] = cfb['name']\n",
    "cfb_diff['year'] = cfb['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_srs = cfb_diff.set_index(['team', 'year']).sort_values(['team', 'year']).shift(1)['simple_rating_system'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfb_diff = cfb_diff.set_index(['team', 'year']).sort_values(['team', 'year'])\n",
    "cfb_diff['prior_srs'] = prior_srs\n",
    "cfb_diff = cfb_diff.reset_index()\n",
    "cfb_diff = cfb_diff.drop(['team', 'year', 'id'], axis = 1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cfb_diff.drop(['simple_rating_system', 'first_downs_from_penalties_diff', 'penalties_diff'], axis = 1)\n",
    "y = cfb_diff['simple_rating_system']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 2.2182330692405707\n",
      "mae 1.1982693406886153\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "model = LinearRegression()\n",
    "scaler = StandardScaler()\n",
    "standardized_X_train = scaler.fit_transform(X_train)\n",
    "standardized_X_test = scaler.transform(X_test)\n",
    "model.fit(standardized_X_train, y_train)\n",
    "y_pred = model.predict(standardized_X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('mse', mean_squared_error(y_test, y_pred))\n",
    "print('mae', mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 2.359189074692517\n",
      "mae 1.2454909568839538\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "scaler = StandardScaler()\n",
    "standardized_X_train = scaler.fit_transform(X_train)\n",
    "standardized_X_test = scaler.transform(X_test)\n",
    "model = linear_model.Lasso(alpha=0.1)\n",
    "model.fit(standardized_X_train, y_train)\n",
    "y_pred = model.predict(standardized_X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('mse', mean_squared_error(y_test, y_pred))\n",
    "print('mae', mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9759282834580087 {'alpha': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "estimator = linear_model.Ridge(alpha=1)\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "grid.fit(standardized_X_train, y_train)\n",
    "\n",
    "print(grid.best_score_ , grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 2.2101614862157737\n",
      "mae 1.1941271858172362\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "scaler = StandardScaler()\n",
    "standardized_X_train = scaler.fit_transform(X_train)\n",
    "standardized_X_test = scaler.transform(X_test)\n",
    "model = linear_model.Ridge(alpha = 1)\n",
    "model.fit(standardized_X_train, y_train)\n",
    "y_pred = model.predict(standardized_X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('mse', mean_squared_error(y_test, y_pred))\n",
    "print('mae', mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975396294975136 {'C': 100, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "estimator = SVR()\n",
    "param_grid = {'C': [0.1, 1, 10, 100],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "grid.fit(standardized_X_train, y_train)\n",
    "\n",
    "print(grid.best_score_ , grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 2.2389553611147797\n",
      "mae 1.1909591071337968\n"
     ]
    }
   ],
   "source": [
    "model = SVR(C=100, gamma=.001)\n",
    "scaler = StandardScaler()\n",
    "standardized_X_train = scaler.fit_transform(X_train)\n",
    "standardized_X_test = scaler.transform(X_test)\n",
    "model.fit(standardized_X_train, y_train)\n",
    "y_pred = model.predict(standardized_X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('mse', mean_squared_error(y_test, y_pred))\n",
    "print('mae', mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666330247392312 {'bootstrap': True, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "estimator = RandomForestRegressor()\n",
    "param_grid = { \n",
    "             \"n_estimators\": [10,20,30,100],\n",
    "             \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "             \"min_samples_split\" : [2,4,8],\n",
    "             \"bootstrap\": [True, False],\n",
    "             }\n",
    "grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "grid.fit(standardized_X_train, y_train)\n",
    "\n",
    "print(grid.best_score_ , grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 2.7614043388214284\n",
      "mae 1.285415357142857\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(bootstrap=True, max_features='auto', min_samples_split=2,n_estimators=100)\n",
    "scaler = StandardScaler()\n",
    "standardized_X_train = scaler.fit_transform(X_train)\n",
    "standardized_X_test = scaler.transform(X_test)\n",
    "model.fit(standardized_X_train, y_train)\n",
    "y_pred = model.predict(standardized_X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('mse', mean_squared_error(y_test, y_pred))\n",
    "print('mae', mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.969689310057972 {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 140}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor as xgb\n",
    "estimator = xgb()\n",
    "param_grid = {\n",
    "    'max_depth': range (2, 10, 1),\n",
    "    'n_estimators': range(60, 220, 40),\n",
    "    'learning_rate': [0.1, 0.01, 0.05]\n",
    "}\n",
    "grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "grid.fit(standardized_X_train, y_train)\n",
    "\n",
    "print(grid.best_score_ , grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 2.5725542772158527\n",
      "mae 1.2734334258485056\n"
     ]
    }
   ],
   "source": [
    "model = xgb(learning_rate=0.05, max_depth=4, n_estimators=140)\n",
    "scaler = StandardScaler()\n",
    "standardized_X_train = scaler.fit_transform(X_train)\n",
    "standardized_X_test = scaler.transform(X_test)\n",
    "model.fit(standardized_X_train, y_train)\n",
    "y_pred = model.predict(standardized_X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('mse', mean_squared_error(y_test, y_pred))\n",
    "print('mae', mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
